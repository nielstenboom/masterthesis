\relax 
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}}
\newlabel{introduction}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Recurring Content Classes}{4}}
\newlabel{section:segmentclasses}{{1.1}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Closing Credits}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Examples of varying types of closing credits}\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{closingcredits}{{1}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Opening credits}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Recaps}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}Bumpers}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Example 'Next' bumper of the dutch television show Expeditie Robinson.}\relax }}{5}}
\newlabel{examplebumper}{{2}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.5}Previews}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Definitions and Techniques}{5}}
\citation{rajam2013survey}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Image Retrieval}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Visual example of image retrieval.}\relax }}{6}}
\newlabel{fig:imageretrieval}{{3}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Feature vectors}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Example of distance in 2D between feature vectors that represent persons. According to the chosen features, the red and blue person are more alike. Image feature vectors will consist of many more dimensions but this cannot be visualized.}\relax }}{7}}
\newlabel{fig:distanceexample}{{4}{7}}
\citation{lienhart1998comparison}
\citation{shao2015shot}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Color histogram with a large binsize (binsize=128) for illustration.}\relax }}{8}}
\newlabel{fig:colorhistogram}{{5}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Shot Change Detection}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Example of a shot change within 4 frames of a video.}\relax }}{8}}
\newlabel{shotchange}{{6}{8}}
\citation{lienhart1997detection}
\citation{gauch2006finding}
\citation{covell2006advertisement}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {The HSV color space.}\relax }}{9}}
\newlabel{hsvspace}{{7}{9}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces \textbf  {Shot boundary detection}\relax }}{9}}
\newlabel{algorithm:shotboundary}{{1}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{9}}
\newlabel{relatedwork}{{2}{9}}
\citation{wang2008multimodal}
\citation{herley2006argos}
\citation{benezeth2010unsupervised}
\citation{abduraman2011unsupervised}
\citation{zheng2018sift}
\citation{smeulders2000content}
\citation{yu2002color}
\citation{manjunath1996texture}
\citation{sivic2003video}
\citation{lowe2004distinctive}
\citation{nister2006scalable}
\citation{philbin2007object}
\citation{jegou2008hamming}
\citation{jegou2010aggregating}
\citation{jegou2012aggregating}
\citation{krizhevsky2012imagenet}
\citation{babenko2014neural}
\citation{yue2015exploiting}
\citation{tolias2015particular}
\citation{beyer1999nearest}
\citation{ffmpeg}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{11}}
\newlabel{methodology}{{3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Feature Vector Construction}{11}}
\citation{faiss}
\citation{faiss-github}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Color Histograms}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Local Color Moments}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}CNN Features}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Matching}{12}}
\bibstyle{ieeetr}
\bibdata{references}
\bibcite{rajam2013survey}{1}
\bibcite{lienhart1998comparison}{2}
\bibcite{shao2015shot}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Diagram of the described methodology. The segment detection process for episode 2 is portrayed.}\relax }}{13}}
\newlabel{fig:diagram}{{8}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{13}}
\newlabel{results}{{4}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{13}}
\newlabel{discussion}{{5}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {6}References}{13}}
\bibcite{lienhart1997detection}{4}
\bibcite{gauch2006finding}{5}
\bibcite{covell2006advertisement}{6}
\bibcite{wang2008multimodal}{7}
\bibcite{herley2006argos}{8}
\bibcite{benezeth2010unsupervised}{9}
\bibcite{abduraman2011unsupervised}{10}
\bibcite{zheng2018sift}{11}
\bibcite{smeulders2000content}{12}
\bibcite{yu2002color}{13}
\bibcite{manjunath1996texture}{14}
\bibcite{sivic2003video}{15}
\bibcite{lowe2004distinctive}{16}
\bibcite{nister2006scalable}{17}
\bibcite{philbin2007object}{18}
\bibcite{jegou2008hamming}{19}
\bibcite{jegou2010aggregating}{20}
\bibcite{jegou2012aggregating}{21}
\bibcite{krizhevsky2012imagenet}{22}
\bibcite{babenko2014neural}{23}
\bibcite{yue2015exploiting}{24}
\bibcite{tolias2015particular}{25}
\bibcite{beyer1999nearest}{26}
\bibcite{ffmpeg}{27}
\bibcite{faiss}{28}
\bibcite{faiss-github}{29}
