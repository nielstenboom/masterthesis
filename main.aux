\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}{section.1}}
\newlabel{introduction}{{1}{4}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Recurring Content Classes}{5}{subsection.1.1}}
\newlabel{section:segmentclasses}{{1.1}{5}{Recurring Content Classes}{subsection.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Frame grabs from each recurring content class.}\relax }}{5}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:introductionexamples}{{1}{5}{\textbf {Frame grabs from each recurring content class.}\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Recaps}{5}{subsubsection.1.1.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Opening credits}{5}{subsubsection.1.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Bumpers}{5}{subsubsection.1.1.3}}
\citation{lienhart1998comparison}
\citation{shao2015shot}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}Previews}{6}{subsubsection.1.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.5}Closing Credits}{6}{subsubsection.1.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Definitions and Techniques}{6}{subsection.1.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Shot Change Detection}{6}{subsubsection.1.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Example of a shot change within 4 frames of a video.}\relax }}{6}{figure.caption.3}}
\newlabel{shotchange}{{2}{6}{\textbf {Example of a shot change within 4 frames of a video.}\relax }{figure.caption.3}{}}
\citation{lienhart1997detection}
\citation{gauch2006finding}
\citation{covell2006advertisement}
\citation{wang2008multimodal}
\citation{herley2006argos}
\citation{benezeth2010unsupervised}
\citation{abduraman2011unsupervised}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces \textbf  {Shot boundary detection}\relax }}{7}{algocf.1}}
\newlabel{algorithm:shotboundary}{{1}{7}{Shot Change Detection}{algocf.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{7}{section.2}}
\newlabel{relatedwork}{{2}{7}{Related Work}{section.2}{}}
\citation{zheng2018sift}
\citation{smeulders2000content}
\citation{yu2002color}
\citation{manjunath1996texture}
\citation{sivic2003video}
\citation{lowe2004distinctive}
\citation{nister2006scalable}
\citation{philbin2007object}
\citation{jegou2008hamming}
\citation{jegou2010aggregating}
\citation{jegou2012aggregating}
\citation{krizhevsky2012imagenet}
\citation{babenko2014neural}
\citation{yue2015exploiting}
\citation{tolias2015particular}
\@writefile{toc}{\contentsline {section}{\numberline {3}Image Retrieval}{8}{section.3}}
\newlabel{section:imageretrieval}{{3}{8}{Image Retrieval}{section.3}{}}
\citation{rajam2013survey}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Visual example of image retrieval.}\relax }}{9}{figure.caption.4}}
\newlabel{fig:imageretrieval}{{3}{9}{\textbf {Visual example of image retrieval.}\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Feature vectors}{9}{subsection.3.1}}
\citation{zheng2018sift}
\citation{yu2002colortexturemoments}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Three images of 10x10 pixels, consisting of only black and white pixels. The resulting feature vectors are $[64,36]^T$, $[0, 100]^T$ and $[25,75]^T$ respectively.\relax }}{10}{figure.caption.5}}
\newlabel{featurevectorimages}{{4}{10}{Three images of 10x10 pixels, consisting of only black and white pixels. The resulting feature vectors are $[64,36]^T$, $[0, 100]^T$ and $[25,75]^T$ respectively.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Example of distance in 2D between feature vectors that represent the example images. According to the chosen features, image 2 and 3 are the most alike.\relax }}{10}{figure.caption.6}}
\newlabel{fig:distanceexample}{{5}{10}{Example of distance in 2D between feature vectors that represent the example images. According to the chosen features, image 2 and 3 are the most alike.\relax }{figure.caption.6}{}}
\citation{yu2002colortexturemoments}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Color Histograms}{11}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Color histogram with a large binsize (binsize=128) for illustration.}\relax }}{11}{figure.caption.7}}
\newlabel{fig:colorhistogram}{{6}{11}{\textbf {Color histogram with a large binsize (binsize=128) for illustration.}\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Color Texture Moments}{11}{subsection.3.3}}
\citation{zheng2018sift}
\citation{tolias2015particular}
\citation{tolias2015particular}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Filters used for computing the color texture channels.}\relax }}{12}{figure.caption.8}}
\newlabel{fig:filters}{{7}{12}{\textbf {Filters used for computing the color texture channels.}\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}CNN Features}{12}{subsection.3.4}}
\newlabel{subsection:cnnfeatures}{{3.4}{12}{CNN Features}{subsection.3.4}{}}
\citation{beyer1999nearest}
\citation{own-github}
\citation{ffmpeg}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{13}{section.4}}
\newlabel{methodology}{{4}{13}{Methodology}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data}{13}{subsection.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Details of the data that was used to perform the experiments with.\relax }}{14}{table.caption.9}}
\newlabel{table:datastatistics}{{1}{14}{Details of the data that was used to perform the experiments with.\relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feature Vector Construction}{14}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Color Histograms}{14}{subsubsection.4.2.1}}
\citation{rmac-github}
\citation{faiss}
\citation{faiss-github}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Color Texture Moments}{15}{subsubsection.4.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}CNN Features}{15}{subsubsection.4.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Matching and Detection}{15}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Diagram of the described methodology. The recurring content detection process for episode 2 is portrayed.}\relax }}{16}{figure.caption.10}}
\newlabel{fig:diagram}{{8}{16}{\textbf {Diagram of the described methodology. The recurring content detection process for episode 2 is portrayed.}\relax }{figure.caption.10}{}}
\citation{lowe2004distinctive}
\citation{lowe2004distinctive}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Recurring Content}{17}{subsubsection.4.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Bumpers}{17}{subsubsection.4.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{17}{section.5}}
\newlabel{results}{{5}{17}{Results}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Recurring Content}{18}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Visual example of the described evaluation methodology.\relax }}{18}{figure.caption.11}}
\newlabel{fig:evaluation-example}{{9}{18}{Visual example of the described evaluation methodology.\relax }{figure.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results of the recurrent content detection at varying values for the lowest percentiles of distances.\relax }}{19}{table.caption.12}}
\newlabel{table:resultsrecurring}{{2}{19}{Results of the recurrent content detection at varying values for the lowest percentiles of distances.\relax }{table.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Precision-Recall curves for each recurrent content class for the percentile values in the range [2.5, 20]. Data points that are in the upper right indicate good performance.\relax }}{19}{figure.caption.13}}
\newlabel{fig:precision-recall}{{10}{19}{Precision-Recall curves for each recurrent content class for the percentile values in the range [2.5, 20]. Data points that are in the upper right indicate good performance.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Bumpers}{20}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Visual example of the described evaluation methodology for bumper detection.\relax }}{20}{figure.caption.14}}
\newlabel{fig:evaluation-example-bumpers}{{11}{20}{Visual example of the described evaluation methodology for bumper detection.\relax }{figure.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Results of the experiments on the bumper detection for varying values of the ratio test.\relax }}{20}{table.caption.15}}
\newlabel{table:resultsbumpers}{{3}{20}{Results of the experiments on the bumper detection for varying values of the ratio test.\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{20}{section.6}}
\newlabel{discussion}{{6}{20}{Discussion}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{21}{section.7}}
\newlabel{conclusion}{{7}{21}{Conclusion}{section.7}{}}
\bibstyle{ieeetr}
\bibdata{references}
\bibcite{lienhart1998comparison}{1}
\bibcite{shao2015shot}{2}
\bibcite{lienhart1997detection}{3}
\bibcite{gauch2006finding}{4}
\bibcite{covell2006advertisement}{5}
\bibcite{wang2008multimodal}{6}
\bibcite{herley2006argos}{7}
\bibcite{benezeth2010unsupervised}{8}
\bibcite{abduraman2011unsupervised}{9}
\bibcite{zheng2018sift}{10}
\bibcite{smeulders2000content}{11}
\@writefile{toc}{\contentsline {section}{\numberline {8}References}{22}{section.8}}
\bibcite{yu2002color}{12}
\bibcite{manjunath1996texture}{13}
\bibcite{sivic2003video}{14}
\bibcite{lowe2004distinctive}{15}
\bibcite{nister2006scalable}{16}
\bibcite{philbin2007object}{17}
\bibcite{jegou2008hamming}{18}
\bibcite{jegou2010aggregating}{19}
\bibcite{jegou2012aggregating}{20}
\bibcite{krizhevsky2012imagenet}{21}
\bibcite{babenko2014neural}{22}
\bibcite{yue2015exploiting}{23}
\bibcite{tolias2015particular}{24}
\bibcite{rajam2013survey}{25}
\bibcite{yu2002colortexturemoments}{26}
\bibcite{beyer1999nearest}{27}
\bibcite{own-github}{28}
\bibcite{ffmpeg}{29}
\bibcite{rmac-github}{30}
\bibcite{faiss}{31}
\bibcite{faiss-github}{32}
