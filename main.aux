\relax 
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}}
\newlabel{introduction}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Recurring Content Classes}{4}}
\newlabel{section:segmentclasses}{{1.1}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}Closing Credits}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Examples of varying types of closing credits}\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{closingcredits}{{1}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}Opening credits}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}Recaps}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}Bumpers}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Example 'Next' bumper of the dutch television show Expeditie Robinson.}\relax }}{5}}
\newlabel{examplebumper}{{2}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.5}Previews}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Definitions and Techniques}{5}}
\citation{lienhart1998comparison}
\citation{shao2015shot}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Shot Change Detection}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Example of a shot change within 4 frames of a video.}\relax }}{6}}
\newlabel{shotchange}{{3}{6}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces \textbf  {Shot boundary detection}\relax }}{6}}
\newlabel{algorithm:shotboundary}{{1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{6}}
\newlabel{relatedwork}{{2}{6}}
\citation{lienhart1997detection}
\citation{gauch2006finding}
\citation{covell2006advertisement}
\citation{wang2008multimodal}
\citation{herley2006argos}
\citation{benezeth2010unsupervised}
\citation{abduraman2011unsupervised}
\citation{zheng2018sift}
\citation{smeulders2000content}
\citation{yu2002color}
\citation{manjunath1996texture}
\citation{sivic2003video}
\citation{lowe2004distinctive}
\citation{nister2006scalable}
\citation{philbin2007object}
\citation{jegou2008hamming}
\citation{jegou2010aggregating}
\citation{jegou2012aggregating}
\citation{krizhevsky2012imagenet}
\citation{babenko2014neural}
\citation{yue2015exploiting}
\citation{tolias2015particular}
\citation{rajam2013survey}
\@writefile{toc}{\contentsline {section}{\numberline {3}Image Retrieval}{8}}
\newlabel{section:imageretrieval}{{3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Visual example of image retrieval.}\relax }}{8}}
\newlabel{fig:imageretrieval}{{4}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Feature vectors}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Three images of 10x10 pixels, consisting of only black and white pixels. The resulting feature vectors are $[64,36]^T$, $[0, 100]^T$ and $[25,75]^T$ respectively.}\relax }}{9}}
\newlabel{featurevectorimages}{{5}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Example of distance in 2D between feature vectors that represent the example images. According to the chosen features, image 2 and 3 are the most alike.}\relax }}{9}}
\newlabel{fig:distanceexample}{{6}{9}}
\citation{zheng2018sift}
\citation{yu2002colortexturemoments}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Color Histograms}{10}}
\citation{yu2002colortexturemoments}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Color histogram with a large binsize (binsize=128) for illustration.}\relax }}{11}}
\newlabel{fig:colorhistogram}{{7}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Color Texture Moments}{11}}
\citation{beyer1999nearest}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Filters used for computing the color texture channels.}\relax }}{12}}
\newlabel{fig:filters}{{8}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}CNN Features}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{12}}
\newlabel{methodology}{{4}{12}}
\citation{ffmpeg}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feature Vector Construction}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Color Histograms}{13}}
\citation{faiss}
\citation{faiss-github}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Local Color Texture Moments}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}CNN Features}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Matching and Detection}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {Diagram of the described methodology. The recurrent content detection process for episode 2 is portrayed.}\relax }}{14}}
\newlabel{fig:diagram}{{9}{14}}
\citation{lowe2004distinctive}
\citation{lowe2004distinctive}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Bumper Detection}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{15}}
\newlabel{results}{{5}{15}}
\bibstyle{ieeetr}
\bibdata{references}
\bibcite{lienhart1998comparison}{1}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Bumper detection}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{16}}
\newlabel{discussion}{{6}{16}}
\bibcite{shao2015shot}{2}
\bibcite{lienhart1997detection}{3}
\bibcite{gauch2006finding}{4}
\bibcite{covell2006advertisement}{5}
\bibcite{wang2008multimodal}{6}
\bibcite{herley2006argos}{7}
\bibcite{benezeth2010unsupervised}{8}
\bibcite{abduraman2011unsupervised}{9}
\bibcite{zheng2018sift}{10}
\bibcite{smeulders2000content}{11}
\bibcite{yu2002color}{12}
\bibcite{manjunath1996texture}{13}
\bibcite{sivic2003video}{14}
\@writefile{toc}{\contentsline {section}{\numberline {7}References}{17}}
\bibcite{lowe2004distinctive}{15}
\bibcite{nister2006scalable}{16}
\bibcite{philbin2007object}{17}
\bibcite{jegou2008hamming}{18}
\bibcite{jegou2010aggregating}{19}
\bibcite{jegou2012aggregating}{20}
\bibcite{krizhevsky2012imagenet}{21}
\bibcite{babenko2014neural}{22}
\bibcite{yue2015exploiting}{23}
\bibcite{tolias2015particular}{24}
\bibcite{rajam2013survey}{25}
\bibcite{yu2002colortexturemoments}{26}
\bibcite{beyer1999nearest}{27}
\bibcite{ffmpeg}{28}
\bibcite{faiss}{29}
\bibcite{faiss-github}{30}
