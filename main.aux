\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{2}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Recurring Content Classes}{3}{section.1.1}}
\newlabel{section:segmentclasses}{{1.1}{3}{Recurring Content Classes}{section.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Recaps}{3}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Visual depiction of recaps. Shots from episode 1 and 2 are shown at the start of episode 3 to give a brief summary of important events.\relax }}{4}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:contextrecaps}{{1.1}{4}{Visual depiction of recaps. Shots from episode 1 and 2 are shown at the start of episode 3 to give a brief summary of important events.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Opening credits}{4}{section*.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Visual depiction of opening credits. A very similar sequence of shots that starts at different times at the beginning of an episode.\relax }}{4}{figure.caption.5}}
\newlabel{fig:contextopeningcredits}{{1.2}{4}{Visual depiction of opening credits. A very similar sequence of shots that starts at different times at the beginning of an episode.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{Bumpers}{4}{section*.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Visual depiction of bumpers. A summary of important shots are shown together that will occur at a later point of time in the episode.\relax }}{5}{figure.caption.7}}
\newlabel{fig:contextbumpers}{{1.3}{5}{Visual depiction of bumpers. A summary of important shots are shown together that will occur at a later point of time in the episode.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Previews}{5}{section*.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Visual depiction of previews. It shows shots that will occur in the next episode with a textual overlay.\relax }}{5}{figure.caption.9}}
\newlabel{fig:contextpreviews}{{1.4}{5}{Visual depiction of previews. It shows shots that will occur in the next episode with a textual overlay.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Closing Credits}{5}{section*.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Visual depiction of closing credits. Frames consisting of text at the end of each episode in which the actors, producers and others related to the show are given credit.\relax }}{6}{figure.caption.11}}
\newlabel{fig:contextclosingcredits}{{1.5}{6}{Visual depiction of closing credits. Frames consisting of text at the end of each episode in which the actors, producers and others related to the show are given credit.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Definitions}{6}{section.1.2}}
\citation{lienhart1997detection}
\citation{gauch2006finding}
\citation{covell2006advertisement}
\citation{wang2008multimodal}
\citation{herley2006argos}
\citation{benezeth2010unsupervised}
\citation{abduraman2011unsupervised}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{7}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{2}{7}{Related Work}{chapter.2}{}}
\citation{zheng2018sift}
\citation{smeulders2000content}
\citation{yu2002color}
\citation{manjunath1996texture}
\citation{sivic2003video}
\citation{lowe2004distinctive}
\citation{nister2006scalable}
\citation{philbin2007object}
\citation{jegou2008hamming}
\citation{jegou2010aggregating}
\citation{jegou2012aggregating}
\citation{krizhevsky2012imagenet}
\citation{babenko2014neural}
\citation{yue2015exploiting}
\citation{tolias2015particular}
\citation{lienhart1998comparison}
\citation{shao2015shot}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Shot Change Detection}{8}{section.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \textbf  {Example of a shot change within 4 frames of a video.}\relax }}{8}{figure.caption.12}}
\newlabel{shotchange}{{2.1}{8}{\textbf {Example of a shot change within 4 frames of a video.}\relax }{figure.caption.12}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces \textbf  {Shot boundary detection}\relax }}{9}{algocf.1}}
\newlabel{algorithm:shotboundary}{{1}{9}{Shot Change Detection}{algocf.1}{}}
\citation{rajam2013survey}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Image Retrieval}{10}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{section:imageretrieval}{{3}{10}{Image Retrieval}{chapter.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Visual example of image retrieval.\relax }}{10}{figure.caption.13}}
\newlabel{fig:imageretrieval}{{3.1}{10}{Visual example of image retrieval.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Feature vectors}{11}{section.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Three images of 10x10 pixels, consisting of only black and white pixels. The resulting feature vectors are $[64,36]^T$, $[0, 100]^T$ and $[25,75]^T$ respectively.\relax }}{11}{figure.caption.14}}
\newlabel{featurevectorimages}{{3.2}{11}{Three images of 10x10 pixels, consisting of only black and white pixels. The resulting feature vectors are $[64,36]^T$, $[0, 100]^T$ and $[25,75]^T$ respectively.\relax }{figure.caption.14}{}}
\citation{zheng2018sift}
\citation{yu2002colortexturemoments}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Example of distance in 2D between feature vectors that represent the example images. According to the chosen features, image 2 and 3 are the most alike.\relax }}{12}{figure.caption.15}}
\newlabel{fig:distanceexample}{{3.3}{12}{Example of distance in 2D between feature vectors that represent the example images. According to the chosen features, image 2 and 3 are the most alike.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Color Histograms}{12}{section.3.2}}
\citation{yu2002colortexturemoments}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Color histogram with a large binsize (binsize=128) for illustration.\relax }}{13}{figure.caption.16}}
\newlabel{fig:colorhistogram}{{3.4}{13}{Color histogram with a large binsize (binsize=128) for illustration.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Color Texture Moments}{13}{section.3.3}}
\citation{krizhevsky2012imagenet}
\citation{zheng2018sift}
\citation{convnet-fig}
\citation{convnet-fig}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Filters used for computing the color texture channels.\relax }}{14}{figure.caption.17}}
\newlabel{fig:filters}{{3.5}{14}{Filters used for computing the color texture channels.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}CNN Features}{14}{section.3.4}}
\newlabel{subsection:cnnfeatures}{{3.4}{14}{CNN Features}{section.3.4}{}}
\citation{tolias2015particular}
\citation{simonyan2014very}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces The working process of a neural network. Image from \cite  {convnet-fig}.\relax }}{15}{figure.caption.18}}
\newlabel{fig:convnet}{{3.6}{15}{The working process of a neural network. Image from \cite {convnet-fig}.\relax }{figure.caption.18}{}}
\citation{beyer1999nearest}
\citation{own-github}
\citation{ffmpeg}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Methodology}{16}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{methodology}{{4}{16}{Methodology}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Data}{16}{section.4.1}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Details of the data that was used to perform the experiments with.\relax }}{17}{table.4.1}}
\newlabel{table:datastatistics}{{4.1}{17}{Details of the data that was used to perform the experiments with.\relax }{table.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Feature Vector Construction}{17}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Color Histograms}{17}{subsection.4.2.1}}
\citation{rmac-github}
\citation{faiss}
\citation{faiss-github}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Color Texture Moments}{18}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}CNN Features}{18}{subsection.4.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Matching and Detection}{18}{section.4.3}}
\citation{faiss-blog}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces \textbf  {Diagram of the described methodology. The recurring content detection process for episode 2 is portrayed.}\relax }}{20}{figure.caption.19}}
\newlabel{fig:diagram}{{4.1}{20}{\textbf {Diagram of the described methodology. The recurring content detection process for episode 2 is portrayed.}\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Recurring Content}{21}{subsection.4.3.1}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces \textbf  {Recurring content detection}\relax }}{22}{algocf.2}}
\newlabel{algorithm:shotboundary}{{2}{22}{Recurring Content}{algocf.2}{}}
\citation{lowe2004distinctive}
\citation{lowe2004distinctive}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Bumpers}{23}{subsection.4.3.2}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces \textbf  {Bumper detection}\relax }}{24}{algocf.3}}
\newlabel{algorithm:shotboundary}{{3}{24}{Bumpers}{algocf.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{25}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{results}{{5}{25}{Results}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Recurring Content}{25}{section.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Visual example of the described evaluation methodology.\relax }}{26}{figure.caption.20}}
\newlabel{fig:evaluation-example}{{5.1}{26}{Visual example of the described evaluation methodology.\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Results of the recurrent content detection at varying values for the percentile threshold. If a distance is belowz the threshold, it is classified as recurring content.\relax }}{26}{table.5.1}}
\newlabel{table:resultsrecurring}{{5.1}{26}{Results of the recurrent content detection at varying values for the percentile threshold. If a distance is belowz the threshold, it is classified as recurring content.\relax }{table.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Bumpers}{26}{section.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Precision-Recall curves for each recurrent content class for the percentile values in the range [2.5, 20]. Data points that are in the upper right indicate good performance.\relax }}{27}{figure.caption.21}}
\newlabel{fig:precision-recall}{{5.2}{27}{Precision-Recall curves for each recurrent content class for the percentile values in the range [2.5, 20]. Data points that are in the upper right indicate good performance.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Visual example of the described evaluation methodology for bumper detection.\relax }}{28}{figure.caption.22}}
\newlabel{fig:evaluation-example-bumpers}{{5.3}{28}{Visual example of the described evaluation methodology for bumper detection.\relax }{figure.caption.22}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Results of the experiments on the bumper detection for varying values of the ratio test.\relax }}{28}{table.5.2}}
\newlabel{table:resultsbumpers}{{5.2}{28}{Results of the experiments on the bumper detection for varying values of the ratio test.\relax }{table.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Discussion}{28}{section.5.3}}
\newlabel{discussion}{{5.3}{28}{Discussion}{section.5.3}{}}
\bibstyle{ieeetr}
\bibdata{references}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{30}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{conclusion}{{6}{30}{Conclusion and Future Work}{chapter.6}{}}
\bibcite{lienhart1997detection}{1}
\bibcite{gauch2006finding}{2}
\bibcite{covell2006advertisement}{3}
\bibcite{wang2008multimodal}{4}
\bibcite{herley2006argos}{5}
\bibcite{benezeth2010unsupervised}{6}
\bibcite{abduraman2011unsupervised}{7}
\bibcite{zheng2018sift}{8}
\bibcite{smeulders2000content}{9}
\bibcite{yu2002color}{10}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Bibliography}{31}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibcite{manjunath1996texture}{11}
\bibcite{sivic2003video}{12}
\bibcite{lowe2004distinctive}{13}
\bibcite{nister2006scalable}{14}
\bibcite{philbin2007object}{15}
\bibcite{jegou2008hamming}{16}
\bibcite{jegou2010aggregating}{17}
\bibcite{jegou2012aggregating}{18}
\bibcite{krizhevsky2012imagenet}{19}
\bibcite{babenko2014neural}{20}
\bibcite{yue2015exploiting}{21}
\bibcite{tolias2015particular}{22}
\bibcite{lienhart1998comparison}{23}
\bibcite{shao2015shot}{24}
\bibcite{rajam2013survey}{25}
\bibcite{yu2002colortexturemoments}{26}
\bibcite{convnet-fig}{27}
\bibcite{simonyan2014very}{28}
\bibcite{beyer1999nearest}{29}
\bibcite{own-github}{30}
\bibcite{ffmpeg}{31}
\bibcite{rmac-github}{32}
\bibcite{faiss}{33}
\bibcite{faiss-github}{34}
\bibcite{faiss-blog}{35}
